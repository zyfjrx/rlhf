{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-10T01:07:00.278612Z",
     "start_time": "2025-10-10T01:06:51.952024Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = \"mps\"\n",
    "model_path = \"/Users/zhangyf/llm/Qwen2-0.5B\"\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T01:07:02.986199Z",
     "start_time": "2025-10-10T01:07:02.983161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(model.generation_config)\n",
    "\n",
    "model.generation_config.do_sample = True\n",
    "model.generation_config.eos_token_id = [151645, 151643]\n",
    "model.generation_config.pad_token_id = 151643\n",
    "model.generation_config.temperature = 0.7\n",
    "model.generation_config.top_p = 0.8\n",
    "model.generation_config.top_k = 20\n",
    "model.generation_config.repetition_penalty = 1.05\n",
    "\n",
    "print(model.generation_config)"
   ],
   "id": "b0187f5e9ac39c3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"max_new_tokens\": 2048\n",
      "}\n",
      "\n",
      "GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.05,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T01:07:05.647486Z",
     "start_time": "2025-10-10T01:07:05.645453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tokenizer.decode(151643))\n",
    "print(tokenizer.decode(151645))"
   ],
   "id": "11b1f6d62a0ba993",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      "<|im_end|>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T01:07:07.561720Z",
     "start_time": "2025-10-10T01:07:07.559382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class SFTConfig:\n",
    "    max_length:int = 2500\n",
    "    batch_size:int = 2\n",
    "    gradient_accumulation_steps:int = 8\n",
    "    log_iter:int = 400\n",
    "    max_lr:float = 2e-5\n",
    "    min_lr:float = 2e-6\n",
    "    warmup_steps:int = 1000"
   ],
   "id": "48355c9f48b4616d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T01:07:10.815314Z",
     "start_time": "2025-10-10T01:07:09.558298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datasets\n",
    "ultrachat_200k_data = datasets.load_dataset('./ultrachat_200k')"
   ],
   "id": "f116655db57617ef",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T01:07:13.039011Z",
     "start_time": "2025-10-10T01:07:13.034111Z"
    }
   },
   "cell_type": "code",
   "source": "ultrachat_200k_data['train_sft'][110]['messages']",
   "id": "ce6a2e4844fddbb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'As I’ve said again and again – Science is everywhere! It’s in the air we breathe, the body we move around in, the nature around us, and the food we eat. It’s even in the sweet treats we enjoy. Yes, Peeps science is a thing. One of our kids’ (and maybe my) favorite things to do with Peeps candy at Easter is put them in the microwave and watch them expand. If you remove them from the microwave before they explode or catch fire, (note: Remove the Peeps before this happens. This can ruin your microwave.) the puffy Peep collapses into a flattened mass of goo. If you plan on eating it, do it fast before it cools and hardens. So what makes the Peep puff up in the microwave and then collapse as it cools? Peeps are made mostly of sugar, water, and gelatin. This mixture is heated and whipped to add air bubbles. This creates the light, fluffy texture of Peeps. As this mixture cools, the gelatin and air bubbles helps the Peeps hold their shape and not flatten. When we heat a Peep in the microwave, the air molecules in the bubbles inside the Peep start moving faster. As the molecules start moving faster, the pressure inside the bubbles begins to increase and push on the walls of the bubbles. The heat of the microwave is, also, starting to cause the sugar in the Peep to soften. So, when as the air molecules push on the sides of the bubbles inside the peep, the bubbles to expand and grow. This is what causes Peeps to get bigger when heated in the microwave. My kids are always disappointed when we take the puffed up Peep from the microwave only to see it instantly deflate. Once the heating stops, the air molecules slow down and stop pushing against the wall of the bubbles and some bubbles burst letting the air out of the Peep. This, plus the fact that some of the water in the Peep evaporates during heating lead to the collapse of the Peep. One day after looking at our deflated Peeps, we talked about the changes that took place in the Peeps do to heating. We thought about the air escaping and the water evaporating and wondered if this caused a change in mass, or weight. Well, there is only one way to find out. Design an experiment! Weigh your glass bowl. If your scale has a tare feature, use it now. If not, record the weight of the bowl. Next, add a Peep to the bowl and record the weight of the Peep. If you do not have a tare feature on your scale, you will have to subtract the weight of the bowl from the weight of the bowl and the Peep to find the weight of the Peep alone. Place the Peep and the bowl in the microwave. Heat for 30 seconds. Immediately after the microwave shuts off, take the bowl and Peep out of the microwave and weigh it. Record the weight of the Peep. Again, subtract the weight of the bowl if you did not use the tare feature. Continue this procedure with new Peeps each time increasing the time by 10 seconds until you have reached 60 seconds. Each time you repeat the experiment, it is called a trial. Record the before and after weights, along with the time for each trial. When all the trials are completed. Subtract the ending weights of each trial from the beginning weights. This is the mass or weight lost in each trial. Graph the amounts of weight lost against the time each Peep was heated. What does the graph look like? Discuss and explain your results. We always have way more peeps than we need to eat so this experiment will be a fun way to use up the extra peeps! Is it possible to do this in an oven? We don’t have a microwave. That would be a great experiment – just to see if this works! Try it out and let me know how it goes. Can you explain why Peeps expand in the microwave and then collapse as they cool?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes, Peeps expand in the microwave as the air molecules in the bubbles inside the Peep start moving faster, causing the pressure inside the bubbles to increase and push on the walls of the bubbles. This, in turn, causes the bubbles to expand and grow. However, when the heating stops, the air molecules slow down, stop pushing against the walls of the bubbles, and some bubbles burst, letting the air out of the Peep. Additionally, some of the water in the Peep evaporates during heating, leading to the collapse of the Peep.',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Can you suggest any other fun experiment that we can do with Peeps candy?',\n",
       "  'role': 'user'},\n",
       " {'content': \"Sure, here's another fun experiment you can do with Peeps candy:\\n\\nPeeps Density Experiment\\nMaterials needed:\\n- Three clear glasses or jars\\n- Water\\n- Salt\\n- Food coloring (optional)\\n- Peeps candy\\n\\nInstructions:\\n1. Fill the first glass with plain water.\\n2. Fill the second glass with water and add a few drops of food coloring (optional).\\n3. Fill the third glass with water and add salt until it is fully dissolved.\\n4. Drop a Peep into each glass and observe what happens.\\n5. Record your observations and note which Peep floats the highest and which sinks the furthest.\\n\\nExplanation:\\nThe Peep in the first glass will float because it is less dense than water. The Peep in the second glass may also float, depending on the amount of food coloring used, as it may increase or decrease the density of the water. The Peep in the third glass will sink because the salt has increased the density of the water, making it more dense than the Peep. The differences in density make for an interesting observation and discussion on buoyancy and density.\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Can you provide me with the recipe for making Peeps candy at home?',\n",
       "  'role': 'user'},\n",
       " {'content': \"Yes, here's a recipe for making Peeps candy at home:\\n\\nHomemade Peeps Recipe\\n\\nIngredients:\\n- 3 packages unflavored gelatin\\n- 1 cup water\\n- 1 1/2 cups granulated sugar\\n- 1 cup light corn syrup\\n- 1/4 teaspoon salt\\n- 1 teaspoon pure vanilla extract\\n- Food coloring\\n- Powdered sugar\\n\\nInstructions:\\n1. In a small saucepan, combine the gelatin and 1/2 cup of water. Let it stand for 5 minutes to soften.\\n2. In a large saucepan, combine the sugar, corn syrup, salt, and the remaining 1/2 cup of water. Cook over medium-high heat, stirring until the sugar dissolves.\\n3. Increase the heat to high and bring the mixture to a boil. Allow it to boil, without stirring, until the mixture reaches 240°F on a candy thermometer.\\n4. Remove from heat and immediately stir in the softened gelatin mixture until it dissolves.\\n5. Add the vanilla extract and stir well.\\n6. Divide the mixture into separate bowls for each color desired. Using a toothpick, add the desired color of food coloring and stir well.\\n7. Allow the mixture to cool to room temperature, or until it no longer feels warm to the touch.\\n8. Scoop the mixture into a piping bag fitted with a round tip. Lightly dust a baking sheet with powdered sugar.\\n9. Pipe the mixture into chick or bunny shapes on the prepared baking sheet.\\n10. Allow the Peeps to dry at room temperature for at least 6 hours or overnight.\\n11. Once dry, dust with additional powdered sugar to coat.\\n\\nEnjoy your homemade Peeps candy!\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Can you explain the science behind why Peeps float in water?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Sure, Peeps float in water because their density is less than that of water. Density is a measure of how much mass is contained in a given volume. When something is less dense than water, it will float on top of the water.\\n\\nPeeps are mostly made up of sugar, which is less dense than water. As a result, when a Peep is placed in water, it displaces an amount of water that weighs more than the Peep itself. This displaced water pushes up on the Peep, causing it to float on the surface of the water.\\n\\nThis is also why objects with a higher density than water, such as a rock, sink to the bottom of the body of water. The displaced water weighs less than the object being submerged, causing the object to sink.\\n\\nSo, in summary, Peeps float in water because they are less dense than water, causing the displaced water to push them up and keep them afloat.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-10T01:07:15.053736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_and_format(data):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        data,\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = False,\n",
    "        truncation = True,\n",
    "        max_length = 2500,\n",
    "    )\n",
    "\n",
    "    return input_ids\n",
    "\n",
    "## 生成训练数据的tokenid\n",
    "chosen_input_ids_list = []\n",
    "i = 0\n",
    "while True:\n",
    "    data = ultrachat_200k_data['train_sft'][i]['messages']\n",
    "    # 添加 **系统提示词**\n",
    "    data.insert(\n",
    "        0,\n",
    "        {\"content\": \"You are a helpful assistant\", \"role\": \"system\"}\n",
    "    )\n",
    "    input_ids = tokenize_and_format(data)\n",
    "    chosen_input_ids_list.append(input_ids)\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"已处理{i}条数据\")\n",
    "    if i == 50000:#len(ultrachat_200k_data['train_sft']):\n",
    "        break\n",
    "print('-' * 70)"
   ],
   "id": "2e2fc1023fbb350b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理1000条数据\n",
      "已处理2000条数据\n",
      "已处理3000条数据\n",
      "已处理4000条数据\n",
      "已处理5000条数据\n",
      "已处理6000条数据\n",
      "已处理7000条数据\n",
      "已处理8000条数据\n",
      "已处理9000条数据\n",
      "已处理10000条数据\n",
      "已处理11000条数据\n",
      "已处理12000条数据\n",
      "已处理13000条数据\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T09:56:43.770005Z",
     "start_time": "2025-10-09T09:56:43.765469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "pprint(tokenizer.decode(chosen_input_ids_list[110]))"
   ],
   "id": "62a6e10466dec9c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|im_start|>system\\n'\n",
      " 'You are a helpful assistant<|im_end|>\\n'\n",
      " '<|im_start|>user\\n'\n",
      " 'As I’ve said again and again – Science is everywhere! It’s in the air we '\n",
      " 'breathe, the body we move around in, the nature around us, and the food we '\n",
      " 'eat. It’s even in the sweet treats we enjoy. Yes, Peeps science is a thing. '\n",
      " 'One of our kids’ (and maybe my) favorite things to do with Peeps candy at '\n",
      " 'Easter is put them in the microwave and watch them expand. If you remove '\n",
      " 'them from the microwave before they explode or catch fire, (note: Remove the '\n",
      " 'Peeps before this happens. This can ruin your microwave.) the puffy Peep '\n",
      " 'collapses into a flattened mass of goo. If you plan on eating it, do it fast '\n",
      " 'before it cools and hardens. So what makes the Peep puff up in the microwave '\n",
      " 'and then collapse as it cools? Peeps are made mostly of sugar, water, and '\n",
      " 'gelatin. This mixture is heated and whipped to add air bubbles. This creates '\n",
      " 'the light, fluffy texture of Peeps. As this mixture cools, the gelatin and '\n",
      " 'air bubbles helps the Peeps hold their shape and not flatten. When we heat a '\n",
      " 'Peep in the microwave, the air molecules in the bubbles inside the Peep '\n",
      " 'start moving faster. As the molecules start moving faster, the pressure '\n",
      " 'inside the bubbles begins to increase and push on the walls of the bubbles. '\n",
      " 'The heat of the microwave is, also, starting to cause the sugar in the Peep '\n",
      " 'to soften. So, when as the air molecules push on the sides of the bubbles '\n",
      " 'inside the peep, the bubbles to expand and grow. This is what causes Peeps '\n",
      " 'to get bigger when heated in the microwave. My kids are always disappointed '\n",
      " 'when we take the puffed up Peep from the microwave only to see it instantly '\n",
      " 'deflate. Once the heating stops, the air molecules slow down and stop '\n",
      " 'pushing against the wall of the bubbles and some bubbles burst letting the '\n",
      " 'air out of the Peep. This, plus the fact that some of the water in the Peep '\n",
      " 'evaporates during heating lead to the collapse of the Peep. One day after '\n",
      " 'looking at our deflated Peeps, we talked about the changes that took place '\n",
      " 'in the Peeps do to heating. We thought about the air escaping and the water '\n",
      " 'evaporating and wondered if this caused a change in mass, or weight. Well, '\n",
      " 'there is only one way to find out. Design an experiment! Weigh your glass '\n",
      " 'bowl. If your scale has a tare feature, use it now. If not, record the '\n",
      " 'weight of the bowl. Next, add a Peep to the bowl and record the weight of '\n",
      " 'the Peep. If you do not have a tare feature on your scale, you will have to '\n",
      " 'subtract the weight of the bowl from the weight of the bowl and the Peep to '\n",
      " 'find the weight of the Peep alone. Place the Peep and the bowl in the '\n",
      " 'microwave. Heat for 30 seconds. Immediately after the microwave shuts off, '\n",
      " 'take the bowl and Peep out of the microwave and weigh it. Record the weight '\n",
      " 'of the Peep. Again, subtract the weight of the bowl if you did not use the '\n",
      " 'tare feature. Continue this procedure with new Peeps each time increasing '\n",
      " 'the time by 10 seconds until you have reached 60 seconds. Each time you '\n",
      " 'repeat the experiment, it is called a trial. Record the before and after '\n",
      " 'weights, along with the time for each trial. When all the trials are '\n",
      " 'completed. Subtract the ending weights of each trial from the beginning '\n",
      " 'weights. This is the mass or weight lost in each trial. Graph the amounts of '\n",
      " 'weight lost against the time each Peep was heated. What does the graph look '\n",
      " 'like? Discuss and explain your results. We always have way more peeps than '\n",
      " 'we need to eat so this experiment will be a fun way to use up the extra '\n",
      " 'peeps! Is it possible to do this in an oven? We don’t have a microwave. That '\n",
      " 'would be a great experiment – just to see if this works! Try it out and let '\n",
      " 'me know how it goes. Can you explain why Peeps expand in the microwave and '\n",
      " 'then collapse as they cool?<|im_end|>\\n'\n",
      " '<|im_start|>assistant\\n'\n",
      " 'Yes, Peeps expand in the microwave as the air molecules in the bubbles '\n",
      " 'inside the Peep start moving faster, causing the pressure inside the bubbles '\n",
      " 'to increase and push on the walls of the bubbles. This, in turn, causes the '\n",
      " 'bubbles to expand and grow. However, when the heating stops, the air '\n",
      " 'molecules slow down, stop pushing against the walls of the bubbles, and some '\n",
      " 'bubbles burst, letting the air out of the Peep. Additionally, some of the '\n",
      " 'water in the Peep evaporates during heating, leading to the collapse of the '\n",
      " 'Peep.<|im_end|>\\n'\n",
      " '<|im_start|>user\\n'\n",
      " 'Can you suggest any other fun experiment that we can do with Peeps '\n",
      " 'candy?<|im_end|>\\n'\n",
      " '<|im_start|>assistant\\n'\n",
      " \"Sure, here's another fun experiment you can do with Peeps candy:\\n\"\n",
      " '\\n'\n",
      " 'Peeps Density Experiment\\n'\n",
      " 'Materials needed:\\n'\n",
      " '- Three clear glasses or jars\\n'\n",
      " '- Water\\n'\n",
      " '- Salt\\n'\n",
      " '- Food coloring (optional)\\n'\n",
      " '- Peeps candy\\n'\n",
      " '\\n'\n",
      " 'Instructions:\\n'\n",
      " '1. Fill the first glass with plain water.\\n'\n",
      " '2. Fill the second glass with water and add a few drops of food coloring '\n",
      " '(optional).\\n'\n",
      " '3. Fill the third glass with water and add salt until it is fully '\n",
      " 'dissolved.\\n'\n",
      " '4. Drop a Peep into each glass and observe what happens.\\n'\n",
      " '5. Record your observations and note which Peep floats the highest and which '\n",
      " 'sinks the furthest.\\n'\n",
      " '\\n'\n",
      " 'Explanation:\\n'\n",
      " 'The Peep in the first glass will float because it is less dense than water. '\n",
      " 'The Peep in the second glass may also float, depending on the amount of food '\n",
      " 'coloring used, as it may increase or decrease the density of the water. The '\n",
      " 'Peep in the third glass will sink because the salt has increased the density '\n",
      " 'of the water, making it more dense than the Peep. The differences in density '\n",
      " 'make for an interesting observation and discussion on buoyancy and '\n",
      " 'density.<|im_end|>\\n'\n",
      " '<|im_start|>user\\n'\n",
      " 'Can you provide me with the recipe for making Peeps candy at '\n",
      " 'home?<|im_end|>\\n'\n",
      " '<|im_start|>assistant\\n'\n",
      " \"Yes, here's a recipe for making Peeps candy at home:\\n\"\n",
      " '\\n'\n",
      " 'Homemade Peeps Recipe\\n'\n",
      " '\\n'\n",
      " 'Ingredients:\\n'\n",
      " '- 3 packages unflavored gelatin\\n'\n",
      " '- 1 cup water\\n'\n",
      " '- 1 1/2 cups granulated sugar\\n'\n",
      " '- 1 cup light corn syrup\\n'\n",
      " '- 1/4 teaspoon salt\\n'\n",
      " '- 1 teaspoon pure vanilla extract\\n'\n",
      " '- Food coloring\\n'\n",
      " '- Powdered sugar\\n'\n",
      " '\\n'\n",
      " 'Instructions:\\n'\n",
      " '1. In a small saucepan, combine the gelatin and 1/2 cup of water. Let it '\n",
      " 'stand for 5 minutes to soften.\\n'\n",
      " '2. In a large saucepan, combine the sugar, corn syrup, salt, and the '\n",
      " 'remaining 1/2 cup of water. Cook over medium-high heat, stirring until the '\n",
      " 'sugar dissolves.\\n'\n",
      " '3. Increase the heat to high and bring the mixture to a boil. Allow it to '\n",
      " 'boil, without stirring, until the mixture reaches 240°F on a candy '\n",
      " 'thermometer.\\n'\n",
      " '4. Remove from heat and immediately stir in the softened gelatin mixture '\n",
      " 'until it dissolves.\\n'\n",
      " '5. Add the vanilla extract and stir well.\\n'\n",
      " '6. Divide the mixture into separate bowls for each color desired. Using a '\n",
      " 'toothpick, add the desired color of food coloring and stir well.\\n'\n",
      " '7. Allow the mixture to cool to room temperature, or until it no longer '\n",
      " 'feels warm to the touch.\\n'\n",
      " '8. Scoop the mixture into a piping bag fitted with a round tip. Lightly dust '\n",
      " 'a baking sheet with powdered sugar.\\n'\n",
      " '9. Pipe the mixture into chick or bunny shapes on the prepared baking '\n",
      " 'sheet.\\n'\n",
      " '10. Allow the Peeps to dry at room temperature for at least 6 hours or '\n",
      " 'overnight.\\n'\n",
      " '11. Once dry, dust with additional powdered sugar to coat.\\n'\n",
      " '\\n'\n",
      " 'Enjoy your homemade Peeps candy!<|im_end|>\\n'\n",
      " '<|im_start|>user\\n'\n",
      " 'Can you explain the science behind why Peeps float in water?<|im_end|>\\n'\n",
      " '<|im_start|>assistant\\n'\n",
      " 'Sure, Peeps float in water because their density is less than that of water. '\n",
      " 'Density is a measure of how much mass is contained in a given volume. When '\n",
      " 'something is less dense than water, it will float on top of the water.\\n'\n",
      " '\\n'\n",
      " 'Peeps are mostly made up of sugar, which is less dense than water. As a '\n",
      " 'result, when a Peep is placed in water, it displaces an amount of water that '\n",
      " 'weighs more than the Peep itself. This displaced water pushes up on the '\n",
      " 'Peep, causing it to float on the surface of the water.\\n'\n",
      " '\\n'\n",
      " 'This is also why objects with a higher density than water, such as a rock, '\n",
      " 'sink to the bottom of the body of water. The displaced water weighs less '\n",
      " 'than the object being submerged, causing the object to sink.\\n'\n",
      " '\\n'\n",
      " 'So, in summary, Peeps float in water because they are less dense than water, '\n",
      " 'causing the displaced water to push them up and keep them '\n",
      " 'afloat.<|im_end|>\\n')\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T09:56:50.483908Z",
     "start_time": "2025-10-09T09:56:50.477182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = SFTConfig.batch_size\n",
    "gradient_accumulation_steps = SFTConfig.gradient_accumulation_steps\n",
    "log_iter = SFTConfig.log_iter\n",
    "max_lr = SFTConfig.max_lr\n",
    "min_lr = SFTConfig.min_lr\n",
    "warmup_steps = SFTConfig.warmup_steps\n",
    "total_steps = len(chosen_input_ids_list) // batch_size\n",
    "optimizer = torch.optim.AdamW(filter(\n",
    "    lambda p: p.requires_grad,\n",
    "    model.parameters()\n",
    "), lr=max_lr)\n",
    "trainable_parameters_num = sum(p.numel() for p in filter(\n",
    "    lambda p: p.requires_grad,\n",
    "    model.parameters())\n",
    ")  ##全参微调"
   ],
   "id": "22f4d72353fb6cd1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T09:56:52.968172Z",
     "start_time": "2025-10-09T09:56:52.961924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##配置logging\n",
    "import time\n",
    "\n",
    "with open(f\"./Qwen2.5-0.5B-SFT_log.txt\", \"a\") as my_file:\n",
    "    my_file.write(f' \\\n",
    "        time:{time.strftime(\"%Y-%m-%d, %H:%M:%S\")}, \\\n",
    "        batch_size:{batch_size}, \\\n",
    "        trainable_parameters_num:{trainable_parameters_num}, \\\n",
    "        warmup_steps:{warmup_steps}, \\\n",
    "        max_lr:{max_lr}, \\\n",
    "        min_lr:{min_lr}\\n')\n",
    "\n",
    "#定义一个日志记录函数\n",
    "def log_call(iters, iters_average_loss):\n",
    "    with open(f\"./Qwen2.5-0.5B-SFT_log.txt\", \"a\") as my_file:\n",
    "        my_file.write(f' \\\n",
    "            time:{time.strftime(\"%Y-%m-%d, %H:%M:%S\")}, \\\n",
    "            iters:{iters+1}, \\\n",
    "            iters_average_Loss:{iters_average_loss:.4f}\\n')"
   ],
   "id": "66ccafae47bfcf5a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T09:56:55.213448Z",
     "start_time": "2025-10-09T09:56:55.209835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_warmup(current_step, warmup_steps, max_lr):\n",
    "    if current_step < warmup_steps:\n",
    "        return max_lr * current_step / warmup_steps\n",
    "    else:\n",
    "        return max_lr\n",
    "\n",
    "def cosine_decay(current_step, warmup_steps, total_steps, max_lr, min_lr):\n",
    "    if current_step < warmup_steps:\n",
    "        return linear_warmup(current_step, warmup_steps, max_lr)\n",
    "    else:\n",
    "        progress = (current_step - warmup_steps)          \\\n",
    "                   /                                      \\\n",
    "                   (total_steps - warmup_steps)\n",
    "        decay = 0.5 * (1 + np.cos(np.pi * progress))\n",
    "        return (max_lr - min_lr) * decay + min_lr"
   ],
   "id": "5cc5f9f818cf6efe",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T09:56:57.860681Z",
     "start_time": "2025-10-09T09:56:57.852791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_answer_mask(input_ids, tokenizer):\n",
    "    \"\"\"\n",
    "    创建仅对助手回答部分计算损失的掩码\n",
    "\n",
    "    Args:\n",
    "        input_ids: 输入token序列 [batch_size, seq_len]\n",
    "        tokenizer: 分词器\n",
    "\n",
    "    Returns:\n",
    "        answer_mask: 助手回答部分为1，其他部分为0的掩码\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = input_ids.shape\n",
    "    answer_mask = torch.zeros_like(input_ids)\n",
    "\n",
    "    # 获取结束标记的token id\n",
    "    eos_token_id = tokenizer.encode('<|im_end|>')[0]\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        # 找到所有 <|im_end|> 的位置\n",
    "        eos_positions = torch.where(\n",
    "            input_ids[batch_idx] == eos_token_id\n",
    "        )[0].tolist()\n",
    "\n",
    "        if len(eos_positions) < 2:  # 至少需要user和assistant各一个结束标记\n",
    "            continue\n",
    "\n",
    "        # 解析对话轮次\n",
    "        user_ends, assistant_ends = \\\n",
    "            _parse_conversation_turns(eos_positions)\n",
    "\n",
    "        # 为每个助手回答设置掩码\n",
    "        _set_answer_masks(\n",
    "            answer_mask[batch_idx],\n",
    "            user_ends,\n",
    "            assistant_ends,\n",
    "            seq_len\n",
    "        )\n",
    "\n",
    "    return answer_mask\n",
    "\n",
    "\n",
    "def _parse_conversation_turns(eos_positions):\n",
    "    \"\"\"\n",
    "    解析对话轮次，分离用户和助手的结束位置\n",
    "\n",
    "    对话格式：\n",
    "    <|im_start|>user\\n{user_msg}<|im_end|>\\n<|im_start|>assistant\\n{assistant_msg}<|im_end|>\\n\n",
    "\n",
    "    eos_positions[0]: system结束 (如果有)\n",
    "    eos_positions[1]: 第1轮user结束\n",
    "    eos_positions[2]: 第1轮assistant结束\n",
    "    eos_positions[3]: 第2轮user结束\n",
    "    eos_positions[4]: 第2轮assistant结束\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # 跳过system系统提示词部分，从第一个user开始\n",
    "    conversation_eos = eos_positions[1:]  # 去掉system的eos\n",
    "\n",
    "    # 奇数索引：user结束位置，偶数索引：assistant结束位置\n",
    "    user_ends = [pos + 1 for pos in conversation_eos[::2]] # 每隔2个取一个，从0开始\n",
    "    assistant_ends = [pos + 1 for pos in conversation_eos[1::2]] # 每隔2个取一个，从1开始\n",
    "\n",
    "    return user_ends, assistant_ends\n",
    "\n",
    "\n",
    "def _set_answer_masks(mask, user_ends, assistant_ends, seq_len):\n",
    "    \"\"\"\n",
    "    为助手回答部分设置掩码\n",
    "\n",
    "    Args:\n",
    "        mask: 当前样本的掩码 [seq_len]\n",
    "        user_ends: 用户消息结束位置列表\n",
    "        assistant_ends: 助手消息结束位置列表\n",
    "        seq_len: 序列长度\n",
    "    \"\"\"\n",
    "    num_user_turns = len(user_ends)\n",
    "    num_assistant_turns = len(assistant_ends)\n",
    "\n",
    "    if num_user_turns == num_assistant_turns:\n",
    "        # 完整对话：每轮都有用户问题和助手回答\n",
    "        for user_end, assistant_end in zip(user_ends, assistant_ends):\n",
    "            answer_start = user_end + 3  # 跳过 <|im_start|>assistant\\n\n",
    "            answer_end = assistant_end - 1  # 不包含 <|im_end|>\n",
    "            mask[answer_start:answer_end] = 1\n",
    "\n",
    "    elif num_user_turns == num_assistant_turns + 1:\n",
    "        # 未完成对话：最后一轮助手回答被截断\n",
    "\n",
    "        # 处理完整的对话轮次\n",
    "        for user_end, assistant_end in zip(user_ends[:-1], assistant_ends):\n",
    "            answer_start = user_end + 3\n",
    "            answer_end = assistant_end - 1\n",
    "            mask[answer_start:answer_end] = 1\n",
    "\n",
    "        # 处理最后一轮被截断的助手回答\n",
    "        last_user_end = user_ends[-1]\n",
    "        last_answer_start = last_user_end + 3\n",
    "        mask[last_answer_start:] = 1  # 到序列结尾"
   ],
   "id": "7ef9a43441698054",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T10:02:52.407375Z",
     "start_time": "2025-10-09T09:57:03.587325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "training_losses = []\n",
    "model.zero_grad()  # 训练开始时清空梯度\n",
    "skipped_batches_count = 0\n",
    "\n",
    "total_batches = len(chosen_input_ids_list) // batch_size\n",
    "\n",
    "for batch_idx in range(total_batches):\n",
    "    ## ==================== 数据准备阶段 ====================\n",
    "\n",
    "    # 获取当前批次的原始数据\n",
    "    current_batch_sequences = chosen_input_ids_list[\n",
    "        batch_idx * batch_size : (batch_idx + 1) * batch_size\n",
    "    ]\n",
    "\n",
    "    # 计算当前批次的最大序列长度，用于padding对齐\n",
    "    max_sequence_length = max([len(sequence) for sequence in current_batch_sequences])\n",
    "\n",
    "    ### 对批次数据进行右填充，使所有序列长度一致以便并行计算\n",
    "    padded_sequences_list = []\n",
    "    pad_token_id = model.generation_config.eos_token_id[-1]\n",
    "\n",
    "    for seq_idx in range(batch_size):\n",
    "        # 原始的一条训练数据\n",
    "        original_sequence = current_batch_sequences[seq_idx]\n",
    "        # 要填充的长度\n",
    "        padding_length = max_sequence_length - len(original_sequence)\n",
    "\n",
    "        # 使用EOS token进行右填充\n",
    "        padded_sequence = torch.nn.functional.pad(\n",
    "            torch.tensor(original_sequence),\n",
    "            (0, padding_length),\n",
    "            mode='constant',\n",
    "            value=pad_token_id\n",
    "        ).tolist()\n",
    "\n",
    "        padded_sequences_list.append(padded_sequence)\n",
    "\n",
    "    # 转换为张量 shape[bs,max_len]\n",
    "    batch_input_tensor = torch.tensor(padded_sequences_list)\n",
    "\n",
    "    ## ==================== 构建输入输出对 ====================\n",
    "\n",
    "    # 构建因果语言模型的输入输出对：x->y（下一个词预测）\n",
    "    model_inputs = batch_input_tensor[:, :-1].to(device)    # 输入：前n-1个token\n",
    "    target_labels = batch_input_tensor[:, 1:].to(device)    # 标签：后n-1个token\n",
    "\n",
    "    ## ==================== 构建训练掩码 ====================\n",
    "\n",
    "    # 构建掩码矩阵来控制损失计算范围\n",
    "    # 1. padding_mask：标识哪些位置是填充token（不计算损失）\n",
    "    # 2. answer_mask：标识哪些位置是助手回答部分（只对回答计算损失）\n",
    "\n",
    "    ### 【填充掩码】：非填充token为1，填充token为0\n",
    "    padding_mask = torch.where(target_labels == pad_token_id, 0, 1)\n",
    "\n",
    "    ### 【回答掩码】：只有助手回答部分为1，其他部分为0\n",
    "    assistant_answer_mask = create_answer_mask(model_inputs, tokenizer)\n",
    "\n",
    "    ### 【组合掩码】：同时满足\"非填充\"且\"是回答部分\"的token才计算损失\n",
    "    final_loss_mask = (assistant_answer_mask & padding_mask)\n",
    "\n",
    "    ## ==================== 批次有效性检查 ====================\n",
    "\n",
    "    # 检查当前批次是否有效：如果某个样本的回答部分完全为空，则跳过该批次\n",
    "    # 这种情况通常发生在问题过长导致回答部分被截断时\n",
    "    tokens_per_sample = final_loss_mask.sum(dim=-1)  # 每个样本的有效回答token数\n",
    "    min_answer_tokens = tokens_per_sample.min().item()  # 最少的有效token数\n",
    "\n",
    "    if min_answer_tokens == 0:\n",
    "        print(f'⚠️ 跳过第{batch_idx + 1}批次：回答部分数据不足')\n",
    "        skipped_batches_count += 1\n",
    "        continue  # 跳过当前批次\n",
    "\n",
    "    ## ==================== 模型前向传播 ====================\n",
    "\n",
    "    # 执行前向传播，获取模型预测的logits\n",
    "    model_logits = model(model_inputs).logits\n",
    "\n",
    "    ## ==================== 损失计算 ====================\n",
    "\n",
    "    # 计算带掩码的交叉熵损失\n",
    "    # 步骤：logits -> softmax -> log -> gather -> 负对数似然 -> 掩码过滤 -> 平均\n",
    "\n",
    "    # 1. 计算每个token的负对数似然损失\n",
    "    log_probabilities = torch.log(torch.softmax(model_logits, dim=-1))\n",
    "    gathered_log_probs = torch.gather(\n",
    "        log_probabilities,\n",
    "        dim=-1,\n",
    "        index=target_labels.unsqueeze(2)\n",
    "    )\n",
    "    negative_log_likelihood = gathered_log_probs * (-1)  # 负对数似然\n",
    "    token_losses = negative_log_likelihood.squeeze(2)\n",
    "\n",
    "    # 2. 应用掩码并计算每个样本的平均损失\n",
    "    masked_token_losses = torch.mul(token_losses, final_loss_mask)\n",
    "    sample_losses = masked_token_losses.sum(dim=-1) \\\n",
    "                  / final_loss_mask.sum(dim=-1)\n",
    "\n",
    "    # 3. 计算批次平均损失并应用梯度累积\n",
    "    batch_average_loss = torch.nanmean(sample_losses) \\\n",
    "                       / gradient_accumulation_steps\n",
    "\n",
    "    ## ==================== 反向传播和优化 ====================\n",
    "\n",
    "    # 反向传播计算梯度\n",
    "    batch_average_loss.backward()\n",
    "\n",
    "    # 动态调整学习率（余弦衰减 + 预热）\n",
    "    current_learning_rate = cosine_decay(\n",
    "        batch_idx,\n",
    "        warmup_steps,\n",
    "        total_steps,\n",
    "        max_lr,\n",
    "        min_lr\n",
    "    )\n",
    "\n",
    "    # 更新优化器的学习率\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = current_learning_rate\n",
    "\n",
    "    # 梯度累积：只在累积步数达到或最后一个批次时更新权重\n",
    "    is_accumulation_step = (batch_idx + 1) \\\n",
    "                         % gradient_accumulation_steps == 0\n",
    "    is_final_batch = (batch_idx + 1) == total_batches\n",
    "\n",
    "    if is_accumulation_step or is_final_batch:\n",
    "        optimizer.step()        # 更新模型权重\n",
    "        optimizer.zero_grad()   # 清空梯度缓存\n",
    "\n",
    "    ## ==================== 训练日志记录 ====================\n",
    "\n",
    "    # 记录当前批次的损失（还原梯度累积的缩放）\n",
    "    actual_batch_loss =                   \\\n",
    "        batch_average_loss.item()         \\\n",
    "        *                                 \\\n",
    "        gradient_accumulation_steps\n",
    "    training_losses.append(actual_batch_loss)\n",
    "\n",
    "    # 定期输出训练进度\n",
    "    should_log = (batch_idx + 1) % log_iter == 0 or is_final_batch\n",
    "\n",
    "    if should_log:\n",
    "        # 计算最近几个批次的平均损失\n",
    "        recent_losses = training_losses[-log_iter:]\n",
    "        recent_average_loss = np.nanmean(recent_losses)\n",
    "\n",
    "        # 输出训练状态\n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f'⏰ 时间: {current_time} | '\n",
    "              f'📊 批次: {batch_idx + 1}/{total_batches} | '\n",
    "              f'📈 最近{len(recent_losses)}批次平均损失: {recent_average_loss:.4f} | '\n",
    "              f'🎯 学习率: {current_learning_rate:.2e}')\n",
    "\n",
    "        # 调用外部日志记录函数\n",
    "        log_call(batch_idx, recent_average_loss)\n",
    "\n",
    "## ==================== 训练完成总结 ====================\n",
    "\n",
    "print(\"🎉 训练完成!\")\n",
    "print(f'📊 训练统计:')\n",
    "print(f'   - 总批次数: {total_batches}')\n",
    "print(f'   - 跳过批次数: {skipped_batches_count}')\n",
    "print(f'   - 有效批次数: {total_batches - skipped_batches_count}')\n",
    "print(f'   - 最终平均损失: {np.nanmean(training_losses[-100:]):.4f}')\n",
    "\n",
    "if skipped_batches_count > 0:\n",
    "    skip_ratio = skipped_batches_count / total_batches * 100\n",
    "    print(f'⚠️ 跳过批次占比: {skip_ratio:.2f}%')\n",
    "    if skip_ratio > 10:\n",
    "        print('💡 建议: 跳过批次过多，考虑增加最大序列长度或优化数据预处理')"
   ],
   "id": "ef896bef4e76290b",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 37.96 GiB, other allocations: 11.74 GiB, max allowed: 47.74 GiB). Tried to allocate 1.14 GiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 107\u001B[0m\n\u001B[1;32m    101\u001B[0m batch_average_loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnanmean(sample_losses) \\\n\u001B[1;32m    102\u001B[0m                    \u001B[38;5;241m/\u001B[39m gradient_accumulation_steps\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m## ==================== 反向传播和优化 ====================\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;66;03m# 反向传播计算梯度\u001B[39;00m\n\u001B[0;32m--> 107\u001B[0m \u001B[43mbatch_average_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;66;03m# 动态调整学习率（余弦衰减 + 预热）\u001B[39;00m\n\u001B[1;32m    110\u001B[0m current_learning_rate \u001B[38;5;241m=\u001B[39m cosine_decay(\n\u001B[1;32m    111\u001B[0m     batch_idx,\n\u001B[1;32m    112\u001B[0m     warmup_steps,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    115\u001B[0m     min_lr\n\u001B[1;32m    116\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/rlhf/lib/python3.10/site-packages/torch/_tensor.py:647\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    637\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    638\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    639\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    640\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    645\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    646\u001B[0m     )\n\u001B[0;32m--> 647\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/rlhf/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    349\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    351\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 354\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/rlhf/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    827\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    828\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 829\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    833\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 37.96 GiB, other allocations: 11.74 GiB, max allowed: 47.74 GiB). Tried to allocate 1.14 GiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
